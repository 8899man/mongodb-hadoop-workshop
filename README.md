# MongoDB-Hadoop Workshop Exercises

MongoDB powers applications as an operational database and Hadoop delivers intelligence as with powerful analytical infrastructure. In this workshop we'll start by learning about how these technologies fit together with the MongoDB Connector for Hadoop. Then we'll cover reading/writing MongoDB data using MapReduce, Pig, Hive, and Spark. Finally, we'll discuss the broader data ecosystem and operational considerations.

## Exercises

Refer to the individual READMEs for steps on building and deploying each exercise.

- [MapReduce](https://github.com/crcsmnky/mongodb-hadoop-workshop/tree/master/mapreduce)
- [Pig](https://github.com/crcsmnky/mongodb-hadoop-workshop/tree/master/pig)
- [Hive](https://github.com/crcsmnky/mongodb-hadoop-workshop/tree/master/hive)
- [Spark](https://github.com/crcsmnky/mongodb-hadoop-workshop/tree/master/spark)